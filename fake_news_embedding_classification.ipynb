{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2077866c",
   "metadata": {},
   "source": [
    "# BERT (Encoder-only-model)\n",
    "\n",
    "- Token classification \n",
    "    NER\n",
    "- Sequence classification\n",
    "    Sentiment Classification\n",
    "    Relation Extraction (RE)\n",
    "- Text Clustering (BERTopic)\n",
    "    Embedding model\n",
    "    Clustering model\n",
    "    使用Representation方法去微調主題表示\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b54574",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# 載入資料集\n",
    "fake_df = pd.read_csv('./raw_data/fake.csv')\n",
    "true_df = pd.read_csv('./raw_data/true.csv')\n",
    "\n",
    "# 加上 label 欄位\n",
    "fake_df['label'] = 1\n",
    "true_df['label'] = 0\n",
    "\n",
    "# 取前1000筆\n",
    "data = pd.concat([fake_df.iloc[:1000], true_df.iloc[:1000]], ignore_index=True)\n",
    "data = data[data['text'].notna()].reset_index(drop=True)\n",
    "\n",
    "# 檢查各類別數量\n",
    "print(data['label'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7b5ac9",
   "metadata": {},
   "source": [
    "## 需要做文本預處理嗎?\n",
    "\n",
    "目的:\n",
    "- 建立分類器來預測真假新聞 -> (TF-IDF + 分類模型需要乾淨的資料，有幫助)\n",
    "- 分析NER 結果與語意分佈 -> (會破壞語意)\n",
    "- 建立主題模型來探索語意主題（BERTopic -> (會破壞語意)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e324aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-z ]', '', text)\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
    "    return tokens\n",
    "\n",
    "data['tokens'] = data['text'].astype(str).apply(preprocess)\n",
    "data['clean_text'] = data['tokens'].apply(lambda x: ' '.join(x))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68ddd12",
   "metadata": {},
   "source": [
    "## NER 預測新聞真假"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81df51b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.font_manager import fontManager\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fontManager.addfont('./public/TaipeiSansTCBeta-Regular.ttf')\n",
    "plt.rcParams['font.sans-serif'] = ['Taipei Sans TC Beta']\n",
    "plt.rcParams['font.size'] = '16'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29def4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from bertopic import BERTopic\n",
    "from bertopic.vectorizers import ClassTfidfTransformer\n",
    "from hdbscan import HDBSCAN\n",
    "from transformers import BertTokenizerFast, AutoTokenizer, AutoModelForTokenClassification, AutoModelForSequenceClassification, pipeline\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 載入模型與 tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"dslim/bert-base-NER\")\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"dslim/bert-base-NER\")\n",
    "ner_pipeline = pipeline(\"ner\", model=model, tokenizer=tokenizer, aggregation_strategy=\"simple\")\n",
    "\n",
    "# 建立 NER 結果列表\n",
    "ner_rows = []\n",
    "\n",
    "# 分切字串\n",
    "def split_text(text, chunk_size=512):\n",
    "    return [text[i:i+chunk_size] for i in range(0, len(text), chunk_size)]\n",
    "\n",
    "# 針對每篇文章跑 NER（可用 tqdm 顯示進度條）\n",
    "for idx, text in tqdm(data['text'].astype(str).items()):\n",
    "    try:\n",
    "        chunks = split_text(text)\n",
    "        all_ents = []\n",
    "        for chunk in chunks:\n",
    "            all_ents.extend(ner_pipeline(chunk))  # 對每段跑 NER\n",
    "        for ent in all_ents:\n",
    "            ner_rows.append({\n",
    "                \"index\": idx,\n",
    "                \"entity\": ent['entity_group'],  # e.g., PER, LOC\n",
    "                \"word\": ent['word'],\n",
    "                \"score\": ent['score']\n",
    "            })\n",
    "    except Exception as e:\n",
    "        print(f\"Error at idx {idx}: {e}\")\n",
    "\n",
    "# 建立 DataFrame\n",
    "ner_df = pd.DataFrame(ner_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875c0283",
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbf7dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 整合 label\n",
    "merged_df = ner_df.merge(data[['label']], left_on='index', right_index=True)\n",
    "\n",
    "# 聚合所有 entity 類型的出現次數\n",
    "entity_counts_all = (\n",
    "    merged_df.groupby(['index', 'entity'])\n",
    "    .size()\n",
    "    .unstack(fill_value=0)  # 得到每篇文章各類實體數\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# 合併 label\n",
    "entity_counts_all = entity_counts_all.merge(data[['label']], left_on='index', right_index=True)\n",
    "\n",
    "# 建模欄位選擇：所有實體類別欄位（排除 index, label）\n",
    "feature_cols = [col for col in entity_counts_all.columns if col not in ['index', 'label']]\n",
    "kmeans_fit_pred_data = entity_counts_all[feature_cols]\n",
    "\n",
    "# 做 KMeans 聚類\n",
    "from sklearn.cluster import KMeans\n",
    "import seaborn as sns\n",
    "\n",
    "kmeans = KMeans(n_clusters=2, random_state=42)\n",
    "entity_counts_all['cluster'] = kmeans.fit_predict(kmeans_fit_pred_data)\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(kmeans_fit_pred_data)\n",
    "entity_counts_all['PC1'] = X_pca[:, 0]\n",
    "entity_counts_all['PC2'] = X_pca[:, 1]\n",
    "# 視覺化聚類結果\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(\n",
    "    data=entity_counts_all,\n",
    "    x='PC1', y='PC2', hue='cluster', style='label',\n",
    "    palette='Set2', s=100\n",
    ")\n",
    "\n",
    "plt.title('NER 特徵的主成分分析 + KMeans 聚類')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e6e5bf",
   "metadata": {},
   "source": [
    "#### 嘗試用 NER 提取出的'人名'、'組織'、'地名數量'作為詞彙特徵，再餵給 TF-IDF + 模型來預測這篇新聞是真/假"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d807d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# 聚合 ner_df 結果為特徵表（以 index = 文章編號為 key）\n",
    "entity_counts = ner_df.groupby(['index', 'entity']).size().unstack(fill_value=0)\n",
    "\n",
    "# 合併回原資料集\n",
    "data_with_ner = data.copy()\n",
    "data_with_ner = data_with_ner.join(entity_counts, how='left').fillna(0)\n",
    "\n",
    "# 建立特徵：人名、組織、地名數量\n",
    "ner_pred_X = data_with_ner[['PER', 'ORG', 'LOC']]\n",
    "ner_pred_y = data_with_ner['label']\n",
    "\n",
    "# 建模\n",
    "# Logistic Regression\n",
    "X_train, X_test, y_train, y_test = train_test_split(ner_pred_X, ner_pred_y, test_size=0.2, random_state=42)\n",
    "lr_clf = LogisticRegression()\n",
    "lr_clf.fit(X_train, y_train)\n",
    "lr_pred = lr_clf.predict(X_test)\n",
    "\n",
    "# Random Forest Classifier\n",
    "rf_clf = RandomForestClassifier(random_state=42)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "rf_y_pred = rf_clf.predict(X_test)\n",
    "\n",
    "# Logistic Regression 結果\n",
    "print(\"=== LogisticRegression 分類結果 ===\")\n",
    "print(classification_report(y_test, lr_pred))\n",
    "\n",
    "# Random Forest 結果\n",
    "print(\"=== RandomForestClassifier 分類結果 ===\")\n",
    "print(classification_report(y_test, rf_y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1e1c16",
   "metadata": {},
   "source": [
    "小結:\n",
    "預測真新聞: 62%被找出，71%準確率\n",
    "precision = 0.71\n",
    "recall = 0.62\n",
    "f1 = 0.66\n",
    "\n",
    "預測假新聞: 74%被找出，66%精確率\n",
    "precision = 0.66\n",
    "recall = 0.74\n",
    "f1 = 0.70\n",
    "\n",
    "NER 特徵對真假新聞辨識有一定程度作用（68% 準確率、F1 達到 0.66–0.70）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400ff9f4",
   "metadata": {},
   "source": [
    "## 使用情緒分析辨識真假新聞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d64c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 載入情緒分析模型\n",
    "model = pipeline(\"sentiment-analysis\", model=\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "# 因為這個語言也是BERT = 效果仰賴'自然語言語序與上下文' = 使用data['text']即可\n",
    "\n",
    "# 切割文字 每段不超過 512 字\n",
    "def split_text(text, chunk_size=512):\n",
    "    return [text[i:i+chunk_size] for i in range(0, len(text), chunk_size)]\n",
    "\n",
    "# 整合段落的情緒分數\n",
    "def analyze_long_text(text):\n",
    "    try:\n",
    "        chunks = split_text(text)\n",
    "        results = model(chunks)\n",
    "\n",
    "        # 統計情緒\n",
    "        pos_scores = [r['score'] for r in results if r['label'] == 'POSITIVE']\n",
    "        neg_scores = [r['score'] for r in results if r['label'] == 'NEGATIVE']\n",
    "\n",
    "        # 平均分數\n",
    "        avg_pos = sum(pos_scores) / len(pos_scores) if pos_scores else 0\n",
    "        avg_neg = sum(neg_scores) / len(neg_scores) if neg_scores else 0\n",
    "\n",
    "        # 決定總體情續\n",
    "        if avg_pos > avg_neg:\n",
    "            return pd.Series(['POSITIVE', avg_pos])\n",
    "        elif avg_neg > avg_pos:\n",
    "            return pd.Series(['NEGATIVE', avg_neg])\n",
    "        else:\n",
    "            return pd.Series(['NEUTRAL', 0.5])\n",
    "    except Exception:\n",
    "        return pd.Series(['ERROR', 0.0])\n",
    "\n",
    "# 執行分析\n",
    "tqdm.pandas()\n",
    "data[['sentiment_label', 'sentiment_score']] = data['text'].progress_apply(analyze_long_text)\n",
    "\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349aa9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_pred_X = data[['sentiment_score']]\n",
    "sentiment_pred_y = data['label']\n",
    "\n",
    "# 分割訓練與測試集\n",
    "X_train, X_test, y_train, y_test = train_test_split(sentiment_pred_X, sentiment_pred_y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 建立模型並訓練\n",
    "lr_clf = LogisticRegression()\n",
    "lr_clf.fit(X_train, y_train)\n",
    "\n",
    "# Random Forest Classifier\n",
    "rf_clf = RandomForestClassifier(random_state=42)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "# 預測與評估\n",
    "y_pred = lr_clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# 預測與評估\n",
    "rf_y_pred = rf_clf.predict(X_test)\n",
    "print(classification_report(y_test, rf_y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcccc87d",
   "metadata": {},
   "source": [
    "### 小結: 情緒預測真假新聞表現不好\n",
    "預測真新聞: 37%被找出，60%準確率\n",
    "precision = 0.60\n",
    "recall = 0.37\n",
    "f1 = 0.46\n",
    "\n",
    "預測假新聞: 75%被找出，54%精確率\n",
    "precision = 0.54\n",
    "recall = 0.75\n",
    "f1 = 0.63\n",
    "\n",
    "整體分類效果偏弱（f1-score 約 0.55）\n",
    "模型偏好預測為假新聞（recall 高），但也多誤判"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e0b838",
   "metadata": {},
   "source": [
    "### 嘗試整合兩者"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec497be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "combined_X = pd.concat([data_with_ner[['PER', 'ORG', 'LOC']], sentiment_pred_X], axis=1)\n",
    "combined_y = data['label']\n",
    "# 分割訓練與測試集\n",
    "X_train, X_test, y_train, y_test = train_test_split(combined_X, combined_y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Logistic Regression\n",
    "clf_lr = LogisticRegression()\n",
    "clf_lr.fit(X_train, y_train)\n",
    "lr_preds = clf_lr.predict(X_test)\n",
    "\n",
    "# Random Forest\n",
    "clf_rf = RandomForestClassifier(random_state=42)\n",
    "clf_rf.fit(X_train, y_train)\n",
    "rf_preds = clf_rf.predict(X_test)\n",
    "\n",
    "# 評估結果\n",
    "print(\"=== Logistic Regression 分類結果 ===\")\n",
    "print(classification_report(y_test, lr_preds))\n",
    "\n",
    "print(\"=== Random Forest 分類結果 ===\")\n",
    "print(classification_report(y_test, rf_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f3f453",
   "metadata": {},
   "source": [
    "NER:\n",
    "=== LogisticRegression 分類結果 ===\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.71      0.62      0.66       201\n",
    "           1       0.66      0.74      0.70       199\n",
    "\n",
    "    accuracy                           0.68       400\n",
    "   macro avg       0.68      0.68      0.68       400\n",
    "weighted avg       0.68      0.68      0.68       400\n",
    "\n",
    "=== RandomForestClassifier 分類結果 ===\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.75      0.74      0.74       201\n",
    "           1       0.74      0.75      0.75       199\n",
    "\n",
    "    accuracy                           0.74       400\n",
    "   macro avg       0.75      0.75      0.74       400\n",
    "weighted avg       0.75      0.74      0.74       400\n",
    "\n",
    "\n",
    "\n",
    "情緒分析:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.60      0.37      0.46       201\n",
    "           1       0.54      0.75      0.63       199\n",
    "\n",
    "    accuracy                           0.56       400\n",
    "   macro avg       0.57      0.56      0.55       400\n",
    "weighted avg       0.57      0.56      0.55       400\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.52      0.50      0.51       201\n",
    "           1       0.52      0.54      0.53       199\n",
    "\n",
    "    accuracy                           0.52       400\n",
    "   macro avg       0.52      0.52      0.52       400\n",
    "weighted avg       0.52      0.52      0.52       400\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "整合後:\n",
    "=== Logistic Regression 分類結果 ===\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.73      0.67      0.70       201\n",
    "           1       0.69      0.75      0.72       199\n",
    "\n",
    "    accuracy                           0.71       400\n",
    "   macro avg       0.71      0.71      0.71       400\n",
    "weighted avg       0.71      0.71      0.71       400\n",
    "\n",
    "=== Random Forest 分類結果 ===\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.80      0.77      0.79       201\n",
    "           1       0.78      0.81      0.79       199\n",
    "\n",
    "    accuracy                           0.79       400\n",
    "   macro avg       0.79      0.79      0.79       400\n",
    "weighted avg       0.79      0.79      0.79       400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6497f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 嘗試增加TF-IDF欄位(clean_text)\n",
    "\n",
    "# 建立 TF-IDF 向量器（可自訂 ngram 範圍與維度限制）\n",
    "tfidf = TfidfVectorizer(max_features=1000, ngram_range=(1, 2))\n",
    "tfidf_matrix = tfidf.fit_transform(data['clean_text'].fillna(''))\n",
    "\n",
    "# 轉為 DataFrame\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf.get_feature_names_out(), index=data.index)\n",
    "\n",
    "# 新增tf-idf欄位\n",
    "ner_sentiment_df = pd.concat([ner_pred_X, sentiment_pred_X], axis=1)\n",
    "combined_X_full = pd.concat([ner_sentiment_df, tfidf_df], axis=1)\n",
    "\n",
    "# 分割資料\n",
    "X_train, X_test, y_train, y_test = train_test_split(combined_X_full, combined_y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Logistic\n",
    "clf_lr = LogisticRegression(max_iter=1000)\n",
    "clf_lr.fit(X_train, y_train)\n",
    "lr_preds = clf_lr.predict(X_test)\n",
    "\n",
    "# Random Forest\n",
    "clf_rf = RandomForestClassifier(random_state=42)\n",
    "clf_rf.fit(X_train, y_train)\n",
    "rf_preds = clf_rf.predict(X_test)\n",
    "\n",
    "# 評估\n",
    "print(\"=== Logistic Regression（NER + Sentiment + TF-IDF） ===\")\n",
    "print(classification_report(y_test, lr_preds))\n",
    "\n",
    "print(\"=== Random Forest（NER + Sentiment + TF-IDF） ===\")\n",
    "print(classification_report(y_test, rf_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa66961",
   "metadata": {},
   "source": [
    "### Topic model: BERTopic 主題詞來源使用c-TF-IDF頻率導向，表現方式偏向詞頻高的詞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19be7f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# 真假新聞進行主題建模\n",
    "docs = data['text'].astype(str).tolist()\n",
    "\n",
    "# 模型可換成 'all-MiniLM-L6-v2', 'microsoft/Phi-4-mini-instruct' 等\n",
    "embedding_model = 'all-MiniLM-L6-v2'\n",
    "\n",
    "# 可調整 測試用2000筆\n",
    "# min_cluster_size 群集最少需要包含n個點，否則會被視為雜訊（noise）\n",
    "# min_samples 包含至少n篇文章的主題才會被承認為主題\n",
    "hdbscan_model = HDBSCAN(min_cluster_size=10, min_samples=30) # Clustering layer\n",
    "vectorizer_model = CountVectorizer(ngram_range=(1, 2), stop_words=\"english\")\n",
    "\n",
    "topic_model = BERTopic(embedding_model=embedding_model, hdbscan_model=hdbscan_model, vectorizer_model=vectorizer_model)\n",
    "topics, probs = topic_model.fit_transform(docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3442db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建立一個儲存所有主題關鍵詞與 TF-IDF 分數的清單\n",
    "all_topics = []\n",
    "\n",
    "# 把主題總數拿出來（排除 -1 是未分類主題）\n",
    "valid_topics = [topic for topic in topic_model.get_topic_info().Topic if topic != -1]\n",
    "\n",
    "# 對每個主題取得詞與 c-TF-IDF 分數\n",
    "for topic_id in valid_topics:\n",
    "    topic_words = topic_model.get_topic(topic_id)\n",
    "    for word, score in topic_words:\n",
    "        all_topics.append({\n",
    "            \"Topic\": topic_id,\n",
    "            \"Word\": word,\n",
    "            \"C-TF-IDF\": score\n",
    "        })\n",
    "\n",
    "# 轉換成 DataFrame 並排序\n",
    "topic_tfidf_df = pd.DataFrame(all_topics)\n",
    "topic_tfidf_df = topic_tfidf_df.sort_values(by=[\"Topic\", \"C-TF-IDF\"], ascending=[True, False])\n",
    "\n",
    "# 顯示前幾列\n",
    "topic_tfidf_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf36076",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 列出文章的BERTopic資訊\n",
    "topic_model.get_document_info(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4088184f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_fake_news_ratio_by_topic(model, docs, labels, title=\"主題的假新聞比例\"):\n",
    "    doc_info = model.get_document_info(docs).copy()\n",
    "    doc_info['label'] = labels\n",
    "\n",
    "    # 計算比例與數量\n",
    "    topic_fake_ratio = (\n",
    "        doc_info[doc_info['Topic'] != -1]\n",
    "        .groupby('Topic')['label']\n",
    "        .mean()\n",
    "        .reset_index()\n",
    "        .rename(columns={'label': 'fake_news_ratio'})\n",
    "    )\n",
    "    topic_counts = (\n",
    "        doc_info[doc_info['Topic'] != -1]['Topic']\n",
    "        .value_counts()\n",
    "        .rename_axis('Topic')\n",
    "        .reset_index(name='count')\n",
    "    )\n",
    "    topic_stats = pd.merge(topic_fake_ratio, topic_counts, on='Topic')\n",
    "\n",
    "    # 加上主題名稱\n",
    "    topic_names = model.get_topic_info()[['Topic', 'Name']]\n",
    "    topic_stats_named = topic_stats.merge(topic_names, on='Topic')\n",
    "\n",
    "    # 過濾比例過低的主題\n",
    "    topic_stats_named = topic_stats_named[topic_stats_named['fake_news_ratio'] >= 0.1]\n",
    "\n",
    "    # 繪圖\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    ax = sns.barplot(\n",
    "        data=topic_stats_named.sort_values(by='fake_news_ratio', ascending=False),\n",
    "        x='fake_news_ratio', y='Name', palette='Reds'\n",
    "    )\n",
    "    plt.title(title)\n",
    "    plt.xlabel('假新聞比例 (label=1)')\n",
    "    plt.ylabel('主題代表詞')\n",
    "    plt.grid(True, axis='x')\n",
    "    ax.set_yticklabels(ax.get_yticklabels(), fontsize=9)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55d4a85",
   "metadata": {},
   "source": [
    "### representation topic model: 加上語意導向的KeyBERT, 表現方式是語意向量相似的詞 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281f408c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bertopic.representation import KeyBERTInspired\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "embedding_model_with_st = SentenceTransformer(embedding_model)  # 或其他你指定的模型\n",
    "embeddings = embedding_model_with_st.encode(docs, show_progress_bar=True)\n",
    "\n",
    "# 關鍵詞表示模型（非生成式）\n",
    "keybert = KeyBERTInspired()\n",
    "\n",
    "# 組裝 representation model\n",
    "representation_model = {\n",
    "    \"KeyBERT\": keybert\n",
    "}\n",
    "\n",
    "# 建立 BERTopic 模型（用 KeyBERT 調整主題表示）\n",
    "representation_topic_model = BERTopic(\n",
    "    embedding_model=embedding_model_with_st,\n",
    "    vectorizer_model=vectorizer_model,\n",
    "    hdbscan_model=hdbscan_model,\n",
    "    representation_model=representation_model,\n",
    "    top_n_words=30,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# 訓練模型\n",
    "topics, probs = representation_topic_model.fit_transform(docs, embeddings)\n",
    "\n",
    "# 查看新的主題表示\n",
    "representation_topic_model.get_topic_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f35ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 視覺化主題分布：圓圈大小是主題的大小，圓圈的距離是主題之間的相似度\n",
    "topic_model.visualize_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c52eb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "representation_topic_model.visualize_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de5782e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 原始模型的主題\n",
    "visualize_fake_news_ratio_by_topic(topic_model, docs, data['label'], title=\"原始主題的假新聞比例\")\n",
    "\n",
    "# 使用 KeyBERT 表示詞的模型主題\n",
    "visualize_fake_news_ratio_by_topic(representation_topic_model, docs, data['label'], title=\"KeyBERT 主題的假新聞比例\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
